{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialog Skill Analysis for Watson Assistant\n",
    "\n",
    "## Introduction\n",
    "Dialog Skill Analysis for Watson Assistant (WA) is intended for use by chatbot designers, developers & data scientists who would like to experiment with and improve on their existing dialog skill design.  \n",
    "\n",
    "We assume familiarity with the Watson Assistant product as well as concepts involved in dialog skill design like intent, entities, utterances etc.   \n",
    "\n",
    "This notebook has been organized into 3 parts based on complexity and expected input from the user.\n",
    "\n",
    "**Part 1**: Training Data Analysis\n",
    "- Analyzes the Watson Assistant dialog skill json already created by the user\n",
    "- Requires the user provide access credentials to an existing WA dialog skill like api_key, workspace_id \n",
    "\n",
    "**Part 2**: Model Analysis\n",
    "- Evaluates the dialog skill against a test set provided by the user\n",
    "- Requires the user provide a test set for model analysis\n",
    "\n",
    "**Part 3**: Advanced Analysis\n",
    "- Analysis related to confidence threshold, term importance etc.\n",
    "- Requires the user provide a test set for model analysis (same data as part 2)\n",
    "\n",
    "### Usage\n",
    "1. Assumes familiarity using a Python Jupyter notebook\n",
    "2. Assumes a Python 3.6 or greater environment\n",
    "3. Install dependencies with `pip install -r requirements.txt`  \n",
    "4. Start jupyter server with `jupyter notebook`\n",
    "5. Select `skill_analysis.ipynb` to start session\n",
    "\n",
    "### Alphabetic Contributor List\n",
    "Watson Assistant Algorithms: Haode Qi, Ladislav Kunc, Ming Tan, Navneet Rao, Panos Karagiannis, Yang Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python libraries\n",
    "import sys, os\n",
    "import json\n",
    "import importlib\n",
    "from collections import Counter\n",
    "\n",
    "# External python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import ibm_watson\n",
    "\n",
    "# Internal python libraries\n",
    "sys.path.append(\"src/main/python\")\n",
    "from utils import skills_util\n",
    "from highlighting import highlighter\n",
    "from data_analysis import summary_generator\n",
    "from data_analysis import divergence_analyzer\n",
    "from data_analysis import similarity_analyzer\n",
    "from term_analysis import chi2_analyzer\n",
    "from term_analysis import keyword_analyzer\n",
    "from term_analysis import entity_analyzer\n",
    "from confidence_analysis import confidence_analyzer\n",
    "from inferencing import inferencer\n",
    "from experimentation import data_manipulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Training Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Access Training Data\n",
    "\n",
    "Please provide access credentials for an existing dialog skill that you would like to analyze.  \n",
    "Have your API Key & Workspace ID values handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(skills_util)\n",
    "\n",
    "# Change Assistant API version if needed\n",
    "# Find Latest --> https://cloud.ibm.com/docs/services/assistant?topic=assistant-release-notes\n",
    "API_VERSION = '2019-02-28'\n",
    "\n",
    "# Change URL based on IBM Cloud datacenter you use   \n",
    "URL = \"https://gateway.watsonplatform.net/assistant/api\" # Dallas (Default US South)\n",
    "\n",
    "#URL = \"https://gateway-s.watsonplatform.net/assistant/api\" # Dallas Staging\n",
    "#URL = \"https://gateway-wdc.watsonplatform.net/assistant/api\" # Washington, DC\n",
    "#URL = \"https://gateway-fra.watsonplatform.net/assistant/api\" # Frankfurt\n",
    "#URL = \"https://gateway-syd.watsonplatform.net/assistant/api\" # Sydney\n",
    "#URL = \"https://gateway-tok.watsonplatform.net/assistant/api\" # Tokyo\n",
    "#URL = \"https://gateway-lon.watsonplatform.net/assistant/api\" # London\n",
    "\n",
    "# By default we only need the IAM API Key & the Workspace ID\n",
    "\n",
    "# If you run the notebook regularly you can uncomment the two lines below\n",
    "# & comment out the line after it\n",
    "#iam_apikey = '###'\n",
    "#workspace_id = '###'\n",
    "#Prompt user for credentials\n",
    "iam_apikey, workspace_id = skills_util.input_credentials()\n",
    "\n",
    "conversation, workspace = skills_util.retrieve_workspace(iam_apikey=iam_apikey,\n",
    "                                                         workspace_id=workspace_id,\n",
    "                                                         url=URL,\n",
    "                                                         api_version=API_VERSION)\n",
    "\n",
    "#If you do not have IAM based API Keys\n",
    "#but have access to a Username, Password & Workspace ID\n",
    "#You can comment out the two lines above & uncomment the lines below to authenticate\n",
    "#username = 'apikey'\n",
    "#password = '###'\n",
    "#workspace_id = '###'\n",
    "#conversation, workspace = skills_util.retrieve_workspace(username=username,\n",
    "#                                                         password=password,\n",
    "#                                                         workspace_id=workspace_id,\n",
    "#                                                         url=URL,\n",
    "#                                                         api_version=API_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract user workspace\n",
    "workspace_data, workspace_vocabulary = skills_util.extract_workspace_data(workspace)\n",
    "entity_dict = conversation.list_entities(workspace_id).get_result()\n",
    "entities_list = [item['entity'] for item in entity_dict['entities']]\n",
    "# Create workspace data frame\n",
    "workspace_pd = pd.DataFrame(workspace_data)\n",
    "\n",
    "display(Markdown(\"### Sample of Utterances & Intents\"))\n",
    "display(HTML(workspace_pd.sample(n = len(workspace_pd) if len(workspace_pd)<10 else 10)\n",
    "             .to_html(index=False)))\n",
    "if entities_list:\n",
    "    display(Markdown(\"### Sample of Entities\"))\n",
    "    display(HTML(pd.DataFrame({\"Entity\":entities_list})\n",
    "                 .sample(n = len(entities_list) if len(entities_list)<10 else 10)\n",
    "                 .to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Process Dialog Skill Training Data\n",
    "\n",
    "We generate summary statistics related to the given skill & workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(summary_generator)\n",
    "summary_generator.generate_summary_statistics(workspace_data, entities_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.2 Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance Analysis\n",
    "\n",
    "We analyze whether the dataset contains class imbalance by checking whether the largest intent contains less than double the number of user examples contained in the smallest intent. Presense of imbalance does not necessarily indicate an issue, please review the actions section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(summary_generator)\n",
    "class_imb_flag = summary_generator.class_imbalance_analysis(workspace_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of User Examples by Intent\n",
    "We display the distribution of intents vs the number of examples per intent (sorted by the number of examples per intent) below. Ideally we should not have large variations in terms of number of user examples for various intents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(summary_generator)\n",
    "summary_generator.scatter_plot_intent_dist(workspace_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(summary_generator)\n",
    "summary_generator.show_user_examples_per_intent(workspace_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions for Class Imbalance\n",
    "\n",
    "Class imbalance will not always lead to lower accuracy. All intents (classes) thus need not have the same number of examples.\n",
    "\n",
    "1. For intents like `updateBankAccount` and `addNewAccountHolder` where the semantics difference between them is more subtle, the number of examples per intent needs to be somewhat balanced else the classifier might favor the intent with the higher number of examples.\n",
    "2. For intents like `greetings` that are semantically distinct from other intents like `updateBankAccount`, it may be okay for it to have fewer examples per intent and still be easy for the intent detector to classify.\n",
    "\n",
    "If during testing it seems like intent classification accuracy is lower than expected, we advise you to re-examine this distribution analysis.  \n",
    "\n",
    "With regard to sorted distribution of examples per intent, if the sorted number of user examples varies a lot across different intents, it can be a potential source of bias for intent detection. Large imbalances in general should be avoided. This can potentially lead to lower accuracy. If your graph displays this characteristic, this might be a source of error.\n",
    "\n",
    "For further guidance on adding more examples to help balance out your distribution, please refer to \n",
    "https://cloud.ibm.com/docs/services/assistant?topic=assistant-intent-recommendations#intent-recommendations-get-example-recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Term Analysis - Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the most correlated unigrams and bigrams for each intent\n",
    "\n",
    "We perform a chi square significance test using count features to determine the terms that are most correlated with each intent in the dataset. \n",
    "\n",
    "A `unigram` is a single word, while a `bigram` is two consecutive words from within the training data. E.g. If you have a sentence like `Thank you for your service`, each of the words in the sentence are considered unigrams while terms like `Thank you`, `your service` are considered bigrams.\n",
    "\n",
    "If you see terms like `hi`, `hello` correlated with a `greeting` intent that would be reasonable. But if you see terms like `table`, `chair` correlated with the `greeting` intent that would be anomalous. A scan of the most correlated unigrams & bigrams for each intent can help you spot potential anomalies within your training data.\n",
    "\n",
    "**Note**: We ignore the following common words from consideration `an, a, in, on, be, or, of, a, and, can, is, to, the, i`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(chi2_analyzer)\n",
    "unigram_intent_dict, bigram_intent_dict = chi2_analyzer.get_chi2_analysis(workspace_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions for Anomalous Correlations\n",
    "\n",
    "If you identify unusual / anomalous correlated terms like: numbers, names etc., which should not be correlated with an intent please read the following:\n",
    "  \n",
    "- **Case 1** : If you see names appearing amongst correlated unigrams or bigrams, add more variation of names so no specific names will be correlated  \n",
    "- **Case 2** : If you see specific numbers like 1234 amongst correlated unigrams or bigrams and are not helpful to the use case, remove or mask these numbers from the examples\n",
    "- **Case 3** : If you see terms which should never be correlated to that specific intent, consider adding or removing terms/examples so that domain specific terms are correlated with the correct intent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Term Analysis - Heat Map\n",
    "\n",
    "A heatmap of terms is a method using which we can visualize which terms or words are frequently occuring within each intent. Rows are the terms and columns are the intents. \n",
    "\n",
    "By default we show only the top 30 intents with the highest number of user examples in the analysis. This number can be changed if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(keyword_analyzer)\n",
    "\n",
    "INTENTS_TO_DISPLAY = 30  # Total number of intents for display\n",
    "MAX_TERMS_DISPLAY = 30  # Total number of terms to display\n",
    "\n",
    "intent_list = []\n",
    "keyword_analyzer.seaborn_heatmap(workspace_pd, INTENTS_TO_DISPLAY, MAX_TERMS_DISPLAY, intent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Analysis for Custom Intent List\n",
    "\n",
    "If you wish to see term analysis for specific intents, feel free to add those intents to the intent list. This shall generate a custom term heatmap. By default we show the top 30 tokens, but this can be changed if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(keyword_analyzer)\n",
    "# intent_list = ['intent1','intent2','intent3'] \n",
    "intent_list = [] \n",
    "\n",
    "\n",
    "MAX_TERMS_DISPLAY = 20  # Total number of terms to display\n",
    "\n",
    "if intent_list: \n",
    "    keyword_analyzer.seaborn_heatmap(workspace_pd, INTENTS_TO_DISPLAY, MAX_TERMS_DISPLAY, intent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions for Anomalous Terms in Heat Map\n",
    "\n",
    "If you notice any terms or words which should not be frequently present within an intent, consider modifying examples in that intent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Ambiguity in Training Data\n",
    "### Uncover possibly ambiguous terms based on feature correlation\n",
    "Based on the chi-square analysis above, we generate intent pairs whose correlated unigrams and bigrams overlap.\n",
    "This allows us to get a glimpse of which unigrams or bigrams might cause potential confusion in intent detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Top Intent Pairs whose correlated unigrams overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(chi2_analyzer)\n",
    "ambiguous_unigram_df = chi2_analyzer.get_confusing_key_terms(unigram_intent_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Top Intent Pairs whose correlated bigrams overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(chi2_analyzer)\n",
    "ambiguous_bigram_df = chi2_analyzer.get_confusing_key_terms(bigram_intent_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Overlap Checker for Specific Intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add specific intent or intent pairs for which you would like to see overlap\n",
    "importlib.reload(chi2_analyzer)\n",
    "intent1 = 'Goodbye'\n",
    "intent2 = ''\n",
    "chi2_analyzer.chi2_overlap_check(ambiguous_unigram_df,ambiguous_bigram_df,intent1,intent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncover ambiguous utterances across intents\n",
    "The following analysis shows user examples that are similar but fall under different Intents.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(similarity_analyzer)\n",
    "similar_utterance_diff_intent_pd = similarity_analyzer.ambiguous_examples_analysis(workspace_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions for Ambiguity in Training Data\n",
    "\n",
    "**Ambiguous Intent Pairs**  \n",
    "If you see terms which are correlated with more than 1 intent, please review if this seems anomalous based on the use case for that intent. If it seems reasonable, it may not be an issue.  \n",
    "\n",
    "**Ambiguous Utterances across intents** \n",
    "1. **Duplicates Utterances**: For duplicate or almost identical utterances, remove those that seem unnecesssary\n",
    "2. **Similar Utterances**: For similar utterances please review the use case for those intents and make sure that they are not accidental additions caused by human error in creating the training data  \n",
    "\n",
    "Reference for more information on entities: https://cloud.ibm.com/docs/services/assistant/services/assistant?topic=assistant-entities\n",
    "\n",
    "For more in-depth analysis related to possible conflicts in your training data across intents, try the conflict detection feature in Watson Assistant https://cloud.ibm.com/docs/services/assistant?topic=assistant-intents#intents-resolve-conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Model Analysis\n",
    "\n",
    "Analyze your existing Watson Assistant Dialog Skill with the help of a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Upload Test Data\n",
    "Please upload a test set in csv/tsv format. Each line in the file should have only `User_Input<tab>Intent`  \n",
    "\n",
    "An example would be\n",
    "```\n",
    "hello how are you<tab>Greeting  \n",
    "I would like to talk to a human<tab>AgentHandoff  \n",
    "```\n",
    "\n",
    "Modify the separator used if you want to use data in csv format rather than tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(skills_util)\n",
    "\n",
    "#Separator: Use '\\t' for tab separated data, ',' for comma separated data\n",
    "separator = '\\t'\n",
    "\n",
    "test_set_path = 'test_set.tsv'\n",
    "test_df = skills_util.process_test_set(test_set_path, separator)\n",
    "\n",
    "display(Markdown(\"### Random Test Sample\"))\n",
    "display(HTML(test_df.sample(n=10).to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Test Data\n",
    "These steps can take time if you have a large test set  \n",
    "\n",
    "<font color=red>**Note**</font>: You will be charged for calls made from this notebook  based on your WA plan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum of 5 threads for faster inference\n",
    "THREAD_NUM = 5\n",
    "full_results = inferencer.inference(conversation,\n",
    "                                    workspace_id,\n",
    "                                    test_df,\n",
    "                                    max_retries=10,\n",
    "                                    max_thread=THREAD_NUM, \n",
    "                                    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(summary_generator)\n",
    "summary_generator.generate_summary_statistics(test_df)\n",
    "summary_generator.show_user_examples_per_intent(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Test Data & Training Data\n",
    "\n",
    "Ideally the Test and Training Data distributions should be similar. The following metrics can help identify gaps between Test Set and Training Set:\n",
    "\n",
    "**1.**  The distribution of User Examples per Intent for the Test Data should be comparable to the Training Data   \n",
    "**2.**  Average length of User Examples for Test and Training Data should be comparable  \n",
    "**3.**  The vocabulary and phrasing of utterances in the Test Data should be comparable to the Training Data\n",
    "\n",
    "If your test data comprises of examples labelled from your logs, and the training data comprises of examples created by human subject matter experts, there may be discrepancies between what the virtual assistant designers thought the end users would type and the way they actually type in production. Thus if you find discrepancies in this section, you might want to consider changing your design to more closely resemble the way end users use your system.\n",
    "\n",
    "<font color=red>**Note**</font>: You will be charged for calls made from this notebook  based on your WA plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(divergence_analyzer)\n",
    "divergence_analyzer.analyze_train_test_diff(workspace_pd, test_df, full_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Overall Accuracy on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(inferencer)\n",
    "results = full_results[['correct_intent', 'top_confidence','top_intent','utterance']]\n",
    "accuracy = inferencer.calculate_accuracy(results)\n",
    "display(Markdown(\"### Accuracy on Test Data: {} %\".format(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "This section gives the user an overview of the errors made by the intent classifier on the test set  \n",
    "\n",
    "**Note** `System Out of Domain` labels are assigned to user examples which get classified with confidence scores less than 0.2 as Watson Assistant would consider them to be irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(inferencer)\n",
    "wrongs_df = inferencer.calculate_mistakes(results)\n",
    "display(Markdown(\"### Intent Detection Mistakes\"))\n",
    "display(Markdown(\"Number of Test Errors: {}\".format(len(wrongs_df))))\n",
    "\n",
    "with pd.option_context('max_colwidth', 250):\n",
    "    if not wrongs_df.empty:\n",
    "        display(wrongs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Advanced Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Analysis using Confidence Thresholds\n",
    "\n",
    "In this phase of the analysis, we illustrate how a confidence threshold which is used to determine what is considered irrelevant or out of domain can be used for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(confidence_analyzer)\n",
    "analysis_df= confidence_analyzer.analysis(results,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Interpretation @ Confidence Level T \n",
    "\n",
    "If a certain confidence threshold T is selected then \n",
    "1. The on topic accuracy for test examples which cross the threshold is ***TOA***\n",
    "2. Percentage of total test examples which returned confidences higher than the threshold measured as ***Bot Coverage %***\n",
    "3. If out of domain examples exist, we falsely accept out of domain examples as on topic examples at a rate measured by ***FAR***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.index = np.arange(1, len(analysis_df)+1)\n",
    "display(analysis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Selection\n",
    "\n",
    "By selecting a higher threshold we can potentially bias our systems towards being more accurate in terms of determining whether an utterance is on topic or out of domain. The default confidence threshold for Watson Assistance is 0.2  \n",
    "\n",
    "**Effect on Accuracy**: When we select a higher threshold T, this can result in higher accuracy (TOA) on those thresholded examples since we are looking at utterances that the intent detector is more confident on.\n",
    "\n",
    "**Effect on Bot Coverage %**: But when we select a higher threshold T, this can also result in less examples being responded to by the virtual assistant.\n",
    "\n",
    "**Deflection to Human Agent**: In the scenarios where the virtual assistant is setup to hand off to a human agent when its less confident, having a higher threshold T can:  \n",
    "\n",
    "1. Improve end user experience when interacting with a virtual assistant, as it is continuing interaction only when its highly confident\n",
    "2. But this can result in higher costs to the customer as this can result in more deflections to the human agents \n",
    "3. There is thus a trade-off and a threshold needs to be decided on a per customer basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Selection on Individual Intents\n",
    "This section allows the examination of thresholds on specific intents.\n",
    "\n",
    "- Use INTENT_LIST = [] to get analysis which averages across all intents\n",
    "- Use INTENT_LIST = ['intent1', 'intent2'] to examine specific intents and threshold analysis on these intents\n",
    "- Use INTENT_LIST = ['ALL_INTENTS'] to examine all intents and threshold analysis for each\n",
    "- Use INTENT_LIST = [MOST_FREQUENT_INTENT] to get analysis on the intent with the most test examples (DEFAULT)\n",
    "\n",
    "**False Acceptance Rate (FAR) for specific intents**  \n",
    "When we calculate FAR across all intents (as in previous section) we calculate fraction of out of domain examples falsely considered on topic. When we calculate FAR for specific intents we calculate the fraction of examples which were falsely predicted to be that specific intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(confidence_analyzer)\n",
    "\n",
    "# Calculate intent with most test examples\n",
    "for label in list(test_df['intent'].value_counts().index):\n",
    "    if label != skills_util.OFFTOPIC_LABEL:\n",
    "        MOST_FREQUENT_INTENT = label \n",
    "        break\n",
    "        \n",
    "# Specify intents of interest for analysis      \n",
    "INTENT_LIST = [MOST_FREQUENT_INTENT]  \n",
    "\n",
    "analysis_df_list = confidence_analyzer.analysis(results, INTENT_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Term Importance Highlighting\n",
    "\n",
    "This intent can be ground-truth or an incorrect predicted intent. It provides term level insights on which terms the classifier thought were important in relation to that specific intent.\n",
    "\n",
    "Even if the system predicts an intent correctly, the terms which the intent classifier though were important may not be as expected by human insight. Human insight might suggest that the intent classifier is focusing on the wrong terms.  \n",
    "\n",
    "The score of each term in the following highlighted images can be viewed as importance factor of that term for that specific intent. The larger the score, the more important the term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the highlighted images for either wrongly-predicted utterances or utterances where the classifier returned a low confidence.   \n",
    "\n",
    "<font color=red>**Note**</font>: You will be charged for calls made from this notebook  based on your WA plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(highlighter)\n",
    "\n",
    "# Pick an example from section 1 which was misclassified\n",
    "# Add the example and correct intent for the example\n",
    "utterance = \"Where is the closest agent?\"  # input example\n",
    "intent = \"General_Connect_to_Agent\"  # input an intent in your workspace which you are interested in.\n",
    "\n",
    "\n",
    "inference_results = inferencer.inference(conversation=conversation, \n",
    "                                    workspace_id=workspace_id, \n",
    "                                    test_data=pd.DataFrame({'utterance':[utterance], \n",
    "                                                            'intent':[intent]}), \n",
    "                                    max_retries = 10, \n",
    "                                    max_thread = 1, \n",
    "                                    verbose = False)\n",
    "\n",
    "highlighter.get_highlights_in_batch_multi_thread(conversation, \n",
    "                                                 workspace_id,\n",
    "                                                 inference_results, \n",
    "                                                 None,\n",
    "                                                 1,\n",
    "                                                 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section below we analyze your test results and produce highlighting for the top 25 problematic utterances which were either mistakes or had confidences below the threshold that was set.    \n",
    "\n",
    "<font color=red>**Note**</font>: You will be charged for calls made from this notebook  based on your WA plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(highlighter)\n",
    "\n",
    "# The output folder for generated images\n",
    "# Note modify this if you want the generated images to be stored in a different directory\n",
    "\n",
    "highlighting_output_folder = './highlighting_images/'\n",
    "if not os.path.exists(highlighting_output_folder):\n",
    "    os.mkdir(highlighting_output_folder)\n",
    "\n",
    "# The threshold the prediction needs to achieve below which  \n",
    "# it will be considered as `out of domain` or `offtopic` utterances. \n",
    "threshold = 0.2\n",
    "\n",
    "# Maximum number of test set examples whose highlighting analysis will be conducted\n",
    "K=25\n",
    "highlighter.get_highlights_in_batch_multi_thread(conversation, \n",
    "                                                 workspace_id,full_results, \n",
    "                                                 highlighting_output_folder,\n",
    "                                                 threshold,\n",
    "                                                 K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Abnormal Confidence Analysis\n",
    "Every test utterance is classified as a specific intent with a specific confidence by the WA intent classifier. It is expected that model would be confident when correctly predicting examples and not highly confident when incorrectly predicting examples. \n",
    "\n",
    "But often this is not true. This may suggest there are anomalies in the design. Examples that are predicted correctly with low confidence and the examples that are predicted incorrectly with high confidence are thus cases which need to be reviewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(confidence_analyzer)\n",
    "correct_thresh, wrong_thresh = 0.3, 0.7\n",
    "correct_with_low_conf_list, incorrect_with_high_conf_list = confidence_analyzer.abnormal_conf(\n",
    "    full_results, correct_thresh, wrong_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(correct_with_low_conf_list) > 0:\n",
    "    display(Markdown(\"#### Examples correctedly predicted with low confidence\"))\n",
    "    with pd.option_context('max_colwidth', 250):\n",
    "        display(HTML(correct_with_low_conf_list.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(incorrect_with_high_conf_list) > 0:\n",
    "    display(Markdown(\"#### Examples incorrectedly predicted with high confidence\"))\n",
    "    with pd.option_context('max_colwidth', 250):\n",
    "        display(HTML(incorrect_with_high_conf_list.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions for abnormal confidence examples\n",
    "\n",
    "If there are examples which are getting classified incorrectly with high confidence for specific intents, it may indicate an issue in the design of those specific intents as the user examples provided for that intent may be overlapping with the design of other intents.\n",
    "\n",
    "If intent A seems to always get misclassified as intent B with high confidence or gets correctly predicted with low confidence, please consider using intent conflict detection https://cloud.ibm.com/docs/services/assistant?topic=assistant-intents#intents-resolve-conflicts\n",
    "\n",
    "Also consider whether those two intents need to be two separate intents or whether they need to be merged. If they can't be merged, then consider adding more user examples which distinguish intent A specifically from intent B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Analysis using Correlated Entities per Intent\n",
    "\n",
    "We perform a chi square significance test for entities as we did for unigrams and bigrams in the previous section. For each utterance in the training data, this analysis will call the mesage api for entity detection on each utterance and find the most correlated entities for each intent\n",
    "\n",
    "<font color=red>**Note**</font>: You will be charged for calls made from this notebook  based on your WA plan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(entity_analyzer)\n",
    "importlib.reload(inferencer)\n",
    "if entities_list:\n",
    "    THREAD_NUM = 5# we allow a maximum of 5 threads for faster inference\n",
    "    train_full_results = inferencer.inference(conversation,\n",
    "                                              workspace_id,\n",
    "                                              workspace_pd,\n",
    "                                              max_retries=10, \n",
    "                                              max_thread=THREAD_NUM,\n",
    "                                              verbose=False)\n",
    "    entity_label_correlation_df = entity_analyzer.entity_label_correlation_analysis(\n",
    "        train_full_results, entities_list)\n",
    "    with pd.option_context('display.max_colwidth', 200):\n",
    "        entity_label_correlation_df.index = np.arange(1, len(entity_label_correlation_df) + 1)\n",
    "        display(entity_label_correlation_df)\n",
    "else:\n",
    "    display(Markdown(\"### Target workspace has no entities.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Glossary\n",
    "\n",
    "**True Positives (TP):** True Positive measures the number of correctly predicted positive values meaning that predicted class is the same as the actual class which is the target intent.\n",
    "\n",
    "**True Negatives (TN):** True Negative measures the number of correctly predicted negative values meaning that the predicted class is the same as the actual class which is not the target intent.\n",
    "\n",
    "**False Positives (FP):** False Positive measures the number of incorrectedly predicted positive values meaning that the predicted class is the target intent but the actual class is not the target intent.  \n",
    "\n",
    "**False Negatives (FN):** False Negatives measures the number of incorrectedly predicted negative values meaning that the predicted class is not the target intent but the actual class is the target intent. \n",
    "\n",
    "**Accuracy:** Accuracy measures the ratio of corrected predicted user examples out of all user examples.   \n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)  \n",
    "\n",
    "**Precision:** Precision measures the ratio of correctly predicted positive observations out of total predicted positive observations.   \n",
    "Precision = TP / (TP + FP)  \n",
    "\n",
    "**Recall:** Recall measures the ratio of correctly predicted positive observations out of all observations of the target intent.  \n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "**F1 Score:** F1 Score is the harmonic average of Precision and Recall.  \n",
    "F1 = 2 \\* (Precision \\* Recall)/ (Precision + Recall)\n",
    "\n",
    "For more information related to Watson Assistant: https://cloud.ibm.com/docs/services/assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
